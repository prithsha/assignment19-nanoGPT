{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpt\n",
    "import os\n",
    "from gpt import GPTLanguageModel, decode, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch21/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2227, val loss 4.2305\n",
      "step 500: train loss 1.7549, val loss 1.9057\n",
      "step 1000: train loss 1.3914, val loss 1.6041\n",
      "step 1500: train loss 1.2676, val loss 1.5255\n",
      "step 2000: train loss 1.1833, val loss 1.5015\n",
      "step 2500: train loss 1.1268, val loss 1.4876\n",
      "step 3000: train loss 1.0723, val loss 1.4855\n",
      "step 3499: train loss 1.0162, val loss 1.4980\n",
      "\n",
      "And God not he be both put up her punished;\n",
      "The aravitation of your discards of your his;\n",
      "And soul informed in arms, his traws rooted to kissubject,\n",
      "Do skings, alLong and men expressites of these sorrow.\n",
      "\n",
      "MAMILLIA:\n",
      "A man strive, 'tis so, much to be sicker;\n",
      "That's my confidented words at I have some inflicted\n",
      "That noble unto my master's.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Good try; and his likely lander departured wars\n",
      "Upon our opinience, and paterful withours.\n",
      "\n",
      "FRIAR Romeo-match; I had witch'd away's but our past\n"
     ]
    }
   ],
   "source": [
    "gpt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "out_dir = 'out'\n",
    "model.load_state_dict(torch.load(os.path.join(out_dir, 'ckpt.pt')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 46, 39, 58, 1, 57, 43, 56, 60, 47, 41, 43, 57, 1, 46, 43, 1, 46, 39, 57, 1, 42, 53, 52, 43, 1, 44, 53, 56, 1, 46, 47, 57, 1, 41, 53, 59, 52, 58, 56, 63, 1, 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"what services he has done for his country ?\"\n",
    "input_tokens = encode(input_text)\n",
    "print(input_tokens)\n",
    "len(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what services he has done for his country ?--\n",
      "He is full too-night, which delivers gloved,\n",
      "Forbed of my pity, In revenge, my live\n",
      "That his deputy tenoment-volt, he\n",
      "The many hath not well deaen?\n",
      "\n",
      "SICINIUS:\n",
      "Dost thought?\n",
      "\n",
      "CORIOLANUS:\n",
      "Apeach old \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, len(input_tokens)), dtype=torch.long, device=device)\n",
    "context[0] = torch.tensor(input_tokens, dtype=torch.long)\n",
    "print(decode(model.generate(context, max_new_tokens=200)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given me them left, good Paulina, with flowers men\n",
      "'Considers;' all alone:' tell me neither thorough for in\n",
      "plock she me them were none speak with me\n",
      "goodly.\n",
      "\n",
      "AUTOLYCUS:\n",
      "I am sure, for the fawn worse, In suffering tranded.\n",
      "\n",
      "POLIXENES:\n",
      "One what's much. Yet, that nence back on the\n",
      "words: how came to y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=300)[0].tolist()))\n",
    "open('more.txt', 'w').write(decode(model.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
