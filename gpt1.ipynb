{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpt\n",
    "import os\n",
    "from gpt import GPTLanguageModel, decode, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "out_dir = 'out'\n",
    "model.load_state_dict(torch.load(os.path.join(out_dir, 'ckpt.pt')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 46, 39, 58, 1, 57, 43, 56, 60, 47, 41, 43, 57, 1, 46, 43, 1, 46, 39, 57, 1, 42, 53, 52, 43, 1, 44, 53, 56, 1, 46, 47, 57, 1, 41, 53, 59, 52, 58, 56, 63, 1, 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"what services he has done for his country ?\"\n",
    "input_tokens = encode(input_text)\n",
    "print(input_tokens)\n",
    "len(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what services he has done for his country ?\n",
      "\n",
      "Second Servant:\n",
      "It stands, sir; and, this inful thing;\n",
      "we'll prove your husband. When we rebest his, I\n",
      "stand will believe your arres: for I do; and power\n",
      "As I will know these sad\n",
      "'Son and must be th\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, len(input_tokens)), dtype=torch.long, device=device)\n",
    "context[0] = torch.tensor(input_tokens, dtype=torch.long)\n",
    "print(decode(model.generate(context, max_new_tokens=200)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Kind Richard and 'twas the moxney.\n",
      "\n",
      "KING RICHARD III:\n",
      "Yea, my Lord,\n",
      "Nobility and myself; wicked us my stay,\n",
      "And buk my crown,\n",
      "Whose vengeanance shall be desert, as I hreceive:\n",
      "My name, as best is at Plewis,\n",
      "My less heavy known and rightly guilty have\n",
      "A fin anger busin.\n",
      "\n",
      "DUKE OF YORK:\n",
      "My dear right.\n",
      "\n",
      "KING RICHARD III:\n",
      "They seem not; in, give me one again.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Well, welcome, gentle Nurse, thither the commony.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "The prettige hath before they keeep the foot!\n",
      "This is my m\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "# open('more.txt', 'w').write(decode(model.generate(context, max_new_tokens=5000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
