{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpt\n",
    "import os\n",
    "from gpt import GPTLanguageModel, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch21/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2227, val loss 4.2305\n",
      "step 500: train loss 1.7549, val loss 1.9057\n",
      "step 1000: train loss 1.3914, val loss 1.6041\n",
      "step 1500: train loss 1.2676, val loss 1.5255\n",
      "step 2000: train loss 1.1833, val loss 1.5015\n",
      "step 2500: train loss 1.1268, val loss 1.4876\n",
      "step 3000: train loss 1.0723, val loss 1.4855\n",
      "step 3499: train loss 1.0162, val loss 1.4980\n",
      "\n",
      "And God not he be both put up her punished;\n",
      "The aravitation of your discards of your his;\n",
      "And soul informed in arms, his traws rooted to kissubject,\n",
      "Do skings, alLong and men expressites of these sorrow.\n",
      "\n",
      "MAMILLIA:\n",
      "A man strive, 'tis so, much to be sicker;\n",
      "That's my confidented words at I have some inflicted\n",
      "That noble unto my master's.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Good try; and his likely lander departured wars\n",
      "Upon our opinience, and paterful withours.\n",
      "\n",
      "FRIAR Romeo-match; I had witch'd away's but our past\n"
     ]
    }
   ],
   "source": [
    "gpt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "out_dir = 'out'\n",
    "model.load_state_dict(torch.load(os.path.join(out_dir, 'ckpt.pt')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If be in feeling,--He cannot commit the glory?\n",
      "\n",
      "First Servant:\n",
      "Ye are not, or twice the had his deposed\n",
      "man and valiant the traitor to the complaine.\n",
      "\n",
      "ARCHIDAPULET:\n",
      "'Sir, five; smell; these peers it is.\n",
      "\n",
      "ANTIGONUS:\n",
      "'This there wakes, 'twas we not men for twenty lames.\n",
      "Look some other examplotter:\n",
      "Ner their poor membreeting at the Policy\n",
      "And I swere to lack them in law perform,\n",
      "Because I would leave no gentleman raid\n",
      "To make on them appear I talk.\n",
      "For jay a thonat back: the bish war home,\n",
      "And giv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "open('more.txt', 'w').write(decode(model.generate(context, max_new_tokens=5000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
